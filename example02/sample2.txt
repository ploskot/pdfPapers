<block:1.1>
 Gunawardena BMC Biology 2014, 12:29  http://www.biomedcentral.com/1741-7007/12/29 
</block:1.1>
<block:1.2>
 REVIEW 
</block:1.2>
<block:1.3>
 Models in biology: 'accurate descriptions of  our pathetic thinking' 
</block:1.3>
<block:1.4>
 Jeremy Gunawardena 
</block:1.4>
<block:1.5>
 Abstract  In this essay I will sketch some ideas for how to think  about models in biology. I will begin by trying to dispel  the myth that quantitative modeling is somehow  foreign to biology. I will then point out the distinction  between forward and reverse modeling and focus  thereafter on the former. Instead of going into  mathematical technicalities about different varieties of  models, I will focus on their logical structure, in terms of  assumptions and conclusions. A model is a logical  machine for deducing the latter from the former. If the  model is correct, then, if you believe its assumptions,  you must, as a matter of logic, also believe its  conclusions. This leads to consideration of the  assumptions underlying models. If these are based on  fundamental physical laws, then it may be reasonable  to treat the model as 'predictive', in the sense that it is  not subject to falsification and we can rely on its  conclusions. However, at the molecular level, models  are more often derived from phenomenology and  guesswork. In this case, the model is a test of its  assumptions and must be falsifiable. I will discuss three  models from this perspective, each of which yields  biological insights, and this will lead to some guidelines  for prospective model builders. 
</block:1.5>
<block:1.6>
 Keywords: Mathematical model, Predictive model,  Fundamental physical laws, Phenomenology,  Membrane-bounded compartment, T-cell receptor,  Somitogenesis clock 
</block:1.6>
<block:1.7>
 The revenge of Erwin Chargaff 
</block:1.7>
<block:1.8>
 When I first came to biology from mathematics, I got  used to being told that there was no place for mathe-  matics in biology. Being a biological novice, I took these  strictures at face value. In retrospect, they proved helpful 
</block:1.8>
<block:1.9>
 Correspondence: jeremy@hms.harvard.edu  Department of Systems Biology, Harvard Medical School, 200 Longwood  Avenue, Boston, USA 
</block:1.9>
<block:1.10>
 because the skepticism encouraged me to let go of my  mathematical past and to immerse myself in experiments.  It was only later, through having to stand up in front of  a class of eager students and say something profound (I  co-teach Harvard's introductory graduate course in Sys-  tems Biology), that I realized how grievously I had been  misled. Biology has some of the finest examples of how  quantitative modeling and measurement have been used  to unravel the world around us [1,2]. The idea that such  methods would not be used would have seemed bizarre  to the biochemist Otto Warburg, the geneticist Thomas  Hunt Morgan, the evolutionary biologist R. A. Fisher,  the structural biologist Max Perutz, the stem-cell biolo-  gists Ernest McCulloch and James Till, the developmental  biologist Conrad Waddington, the physiologist Arthur  Guyton, the neuroscientists Alan Hodgkin and Andrew  Huxley, the immunologist Niels Jerne, the pharmacologist  James Black, the epidemiologist Ronald Ross, the ecolo-  gist Robert MacArthur and to others more or less well  known.  Why is it that biologists have such an odd perception of  their own discipline? I attribute this to two factors. The  first is an important theme in systems biology [3,4]: the  mean may not be representative of the distribution. Otto  Warburg is a good example. In the eyes of his contempo-  raries, Warburg was an accomplished theorist: 'to develop  the mathematical analysis of the measurements required  very exceptional experimental and theoretical skill' [5].  Once Warburg had opened the door, however, it became  easy for those who followed him to avoid acquiring the  same skills. Of Warburg's three assistants who won Nobel  Prizes, one would not describe Hans Krebs or Hugo Theo-  rell as 'theoretically skilled', although Otto Meyerhoff was  certainly quantitative. On average, theoretical skills recede  into the long tail of the distribution, out of sight of the  conventional histories and textbooks. It is high time for  a revisionist account of the history of biology to restore  quantitative reasoning to its rightful place.  The second factor is the enormous success of molecu-  lar biology. This is ironic, for many of the instigators of  that revolution were physicists: Erwin Schr?dinger, Max 
</block:1.10>
<block:1.11>
 (C) 2014 Gunawardena; licensee BioMed Central Ltd. This is an Open Access article distributed under the terms of the Creative  Commons Attribution License (http://creativecommons.org/licenses/by/4.0), which permits unrestricted use, distribution, and  reproduction in any medium, provided the original work is properly credited. The Creative Commons Public Domain Dedication  waiver (http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise  stated. 
</block:1.11>
<block:2.1>
 Gunawardena BMC Biology 2014, 12:29  http://www.biomedcentral.com/1741-7007/12/29 
</block:2.1>
<block:2.2>
 Delbr?ck, Francis Crick, Leo Szilard, Seymour Benzer and  Wally Gilbert. There was, in fact, a brief window, dur-  ing the life of physicist George Gamow's RNA Tie Club,  when it was claimed, with poor judgment, that physics and  information theory could work out the genetic code [6,7].  Erwin Chargaff, who first uncovered the complementar-  ity of the A-T and G-C nucleotide pairs (Chargaff 's rules),  was nominally a member of the club--his code name was  lysine--but I doubt that he was taken in by such theo-  retical pretensions. He famously described the molecular  biology of the time as 'the practice of biochemistry with-  out a license' [8]. When Marshall Nirenberg and Heinrich  Matthaei came out of nowhere to make the first crack in  the genetic code [9], thereby showing that licensing was  mandatory--one can just sense the smile on Chargaff 's  face--the theorists of the day must have felt that the bar-  barians were at the gates of Rome. Molecular biology  never recovered from this historic defeat of theory and  there have been so many interesting genes to characterize  since, it has never really needed to.  It is the culmination of molecular biology in the genome  projects that has finally brought diminishing returns to  the one gene, ten PhDs way of life. We now think we know  most of the genes and the interesting question is no longer  characterizing this or that gene but, rather, understanding  how the various molecular components collectively give  rise to phenotype and physiology. We call this systems  biology. It is a very different enterprise. It has brought into  biology an intrusion of aliens and concepts from physics,  mathematics, engineering and computer science and a  renewed interest in the role of quantitative reasoning and  modeling, to which we now turn. 
</block:2.2>
<block:2.3>
 Forward and reverse modeling 
</block:2.3>
<block:2.4>
 We can distinguish two kinds of modeling strategy in  the current literature. We can call them forward and  reverse modeling. Reverse modeling starts from experi-  mental data and seeks potential causalities suggested by  the correlations in the data, captured in the structure  of a mathematical model. Forward modeling starts from  known, or suspected, causalities, expressed in the form of  a model, from which predictions are made about what to  expect.  Reverse modeling has been widely used to analyze the  post-genome, -omic data glut and is sometimes mistak-  enly equated with systems biology [10]. It has occasionally  suggested new conceptual ideas but has more often been  used to suggest new molecular components or interac-  tions, which have then been confirmed by conventional  molecular biological approaches. The models themselves  have been of less significance for understanding system  behavior than as a mathematical context in which statis-  tical inference becomes feasible. In contrast, most of our  understanding of system behavior, as in concepts such 
</block:2.4>
<block:2.5>
 Page 2 of 11 
</block:2.5>
<block:2.6>
 as homeostasis, feedback, canalization and noise, have  emerged from forward modeling.  I will focus below on the kinds of models used in for-  ward modeling. This is not to imply that reverse modeling  is unimportant or uninteresting. There are many situa-  tions, especially when dealing with physiological or clin-  ical data, where the underlying causalities are unknown  or hideously complicated and a reverse-modeling strat-  egy makes good sense. But the issues in distilling causality  from correlation deserve their own treatment, which lies  outside the scope of the present essay [11]. 
</block:2.6>
<block:2.7>
 The logical structure of models 
</block:2.7>
<block:2.8>
 Mathematical models come in a variety of flavors, depend-  ing on whether the state of a system is measured in  discrete units ('off ' and 'on'), in continuous concentra-  tions or as probability distributions and whether time  and space are themselves treated discretely or contin-  uously. The resulting menagerie of ordinary differential  equations, partial differential equations, delay differential  equations, stochastic processes, finite-state automata, cel-  lular automata, Petri nets, hybrid models, ... each have  their specific technical foibles and a vast associated tech-  nical literature. It is easy to get drowned by these techni-  calities, while losing sight of the bigger picture of what the  model is telling us. Underneath all that technical variety,  each model has the same logical structure.  Any mathematical model, no matter how complicated,  consists of a set of assumptions, from which are deduced  a set of conclusions. The technical machinery specific to  each flavor of model is concerned with deducing the latter  from the former. This deduction comes with a guarantee,  which, unlike other guarantees, can never be invalidated.  Provided the model is correct, if you accept its assump-  tions, you must as a matter of logic also accept its con-  clusions. If 'Socrates is a man' and 'All men are mortal'  then you cannot deny that 'Socrates is mortal'. The deduc-  tive process that leads from assumptions to conclusions  involves much the same Aristotelian syllogisms disguised  in the particular technical language appropriate to the  particular flavor of model being used or, more often, yet  further disguised in computer-speak. This guarantee of  logical rigor is a mathematical model's unique benefit.  Note, however, the fine print: 'provided the model is  correct'. If the deductive reasoning is faulty, one can draw  any conclusion from any assumption. There is no guar-  antee that a model is correct (only a guarantee that if it  is correct then the conclusions logically follow from the  assumptions). We have to hope that the model's makers  have done it right and that the editors and the review-  ers have done their jobs. The best way to check this is  to redo the calculations by a different method. This is  rarely easy but it is what mathematicians do within math-  ematics itself. Reproducibility improves credibility. We 
</block:2.8>
<block:3.1>
 Gunawardena BMC Biology 2014, 12:29  http://www.biomedcentral.com/1741-7007/12/29 
</block:3.1>
<block:3.2>
 may not have a guarantee that a model is correct but  we can become more (or less) confident that it is. The  practice of mathematics is not so very different from the  experimental world after all.  The correctness of a model is an important issue that is  poorly addressed by the current review process. However,  it can be addressed as just described. From now on, I will  assume the correctness of any model being discussed and  will take its guarantee of logical validity at face value.  The guarantee tells us that the conclusions are already  wrapped up in the assumptions, of which they are a log-  ical consequence. This is not to say that the conclusions  are obvious. This may be far from the case and the deduc-  tive process can be extremely challenging. However, that  is a matter of mathematical technique. It should not dis-  tract from what is important for the biology, which is the  set of assumptions, or the price being paid for the conclu-  sions being drawn. Instead of asking whether we believe  a model's conclusions, we should be asking whether we  believe the model's assumptions. What basis do we have  for doing so? 
</block:3.2>
<block:3.3>
 On making assumptions 
</block:3.3>
<block:3.4>
 Biology rests on physics. At the length scales and  timescales relevant to biology, physicists have worked out  the fundamental laws governing the behavior of matter.  If our assumptions can be grounded in physics, then it  seems that our models should be predictive, in the sense  that they are not subject to falsification--that issue has  already been taken care of with the fundamental laws--  so that we can be confident of the conclusions drawn.  Physicists would make an even stronger claim on the  basis that, at the fundamental level, there is nothing other  than physics. As Richard Feynman put it, 'all things are  made of atoms and ... everything that living things do can  be understood in terms of the jigglings and wigglings of  atoms' [12, Chapter 3-3]. This suggests that provided we  have included all the relevant assumptions in our mod-  els then whatever is to be known should emerge from our  calculations. Models based on fundamental physical laws  appear in this way to be objective descriptions of reality,  which we can interrogate to understand reality. This vision  of the world and our place in it has been powerful and  compelling.  Can we ground biological models on fundamental phys-  ical laws? The Schr?dinger equation even for a single  protein is too hideously complicated to solve directly.  There is, however, one context in which it can be approx-  imated. Not surprisingly, this is at the atomic scale of  which Feynman spoke, where molecular dynamics mod-  els can capture the jigglings and wigglings of the atoms  of a protein in solution or in a lipid membrane in  terms of physical forces [13]. With improved comput-  ing resources, including purpose-built supercomputers, 
</block:3.4>
<block:3.5>
 Page 3 of 11 
</block:3.5>
<block:3.6>
 such molecular dynamics models have provided novel  insights into the functioning of proteins and multi-protein  complexes [14,15]. The award of the 2013 Nobel Prize  in Chemistry to Martin Karplus, Michael Levitt and  Arieh Warshel recognizes the broad impact of these  advances.  As we move up the biological scale, from atoms to  molecules, we enter a different realm, of chemistry, or bio-  chemistry, rather than physics. But chemistry is grounded  in physics, is it not? Well, so they say but let us see what  actually happens when we encounter a chemical reaction 
</block:3.6>
<block:3.7>
 A + B -> C 
</block:3.7>
<block:3.8>
 and want to study it quantitatively. To determine the rate  of such a reaction, the universal practice in biology is to  appeal to the law of mass action, which says that the rate  is proportional to the product of the concentrations of the  reactants, from which we deduce that 
</block:3.8>
<block:3.9>
 d[C]  = k[A] [B] ,  dt 
</block:3.9>
<block:3.10>
 where [-] denotes concentration and k is the constant  of proportionality. Notice the immense convenience that  mass action offers, for we can jump from reaction to math-  ematics without stopping to think about the chemistry.  There is only one problem. This law of mass action is not  chemistry. A chemist might point out, for instance, that  the reaction of hydrogen and bromine in the gas phase to  form hydrobromic acid, 
</block:3.10>
<block:3.11>
 H 2 + Br 2 -> 2HBr, 
</block:3.11>
<block:3.12>
 has a rate of reaction given by 
</block:3.12>
<block:3.13>
 k 1 [H 2 ] [Br 2 ] 3/2  d[HBr]  =  ,  dt  [Br 2 ] +k 2 [HBr] 
</block:3.13>
<block:3.14>
 which is rather far from what mass action claims, and  that, in general, you cannot deduce the rate of a reaction  from its stoichiometry [16]. (For more about the tangled  tale of mass action, see [17], from which this example is  thieved.) Mass action is not physics or even chemistry, it is  phenomenology: a mathematical formulation, which may  account for observed behavior but which is not based on  fundamental laws.  Actually, mass action is rather good phenomenology.  It has worked well to account for how enzymes behave,  starting with Michaelis and Menten and carrying on right  through to the modern era [18]. It is certainly more prin-  cipled than what is typically done when trying to convert  biological understanding into mathematical assumptions.  If A is known to activate B--perhaps A is a transcription  factor and B a protein that is induced by A--then it is 
</block:3.14>
<block:4.1>
 Gunawardena BMC Biology 2014, 12:29  http://www.biomedcentral.com/1741-7007/12/29 
</block:4.1>
<block:4.2>
 Page 4 of 11 
</block:4.2>
<block:4.3>
 not unusual to find activation summarized in some Hill  function of the form 
</block:4.3>
<block:4.4>
 M[A] h  d[B]  = h  ,  dt  K +[A] h 
</block:4.4>
<block:4.5>
 (1) 
</block:4.5>
<block:4.6>
 for which, as Hill himself well understood and has been  repeatedly pointed out [19], there is almost no realistic  biochemical justification. It is, at best, a guess.  The point here is not that we should not guess; we often  have no choice but to do so. The point is to acknowledge  the consequences of phenomenology and guessing for the  kinds of models we make. They are no longer objective  descriptions of reality. They can no longer be considered  predictive, in the sense of physics or even of molecular  dynamics. What then are they?  One person who understood the answer was the phar-  macologist James Black [20]. Pharmacology has been  a quantitative discipline almost since its inception and  mathematical models have formed the basis for much of  our understanding of how drugs interact with receptors  [21]. (Indeed, models were the basis for understanding  that there might be such entities as receptors in the first  place [2]). Black used mathematical models on the road  that led to the first beta-adrenergic receptor antagonists,  or beta blockers, and in his lecture for the 1988 Nobel  Prize in Physiology or Medicine he crystallized his under-  standing of them in a way that nobody has ever bettered:  'Models in analytical pharmacology are not meant to be  descriptions, pathetic descriptions, of nature; they are  designed to be accurate descriptions of our pathetic think-  ing about nature' [22]. Just substitute 'systems biology'  for 'analytical pharmacology' and you have it. Black went  on to say about models that: 'They are meant to expose  assumptions, define expectations and help us to devise  new tests'.  An important difference arises between models like this,  which are based on phenomenology and guesswork, and  models based on fundamental physics. If the model is not  going to be predictive and if we are not certain of its  assumptions, then there is no justification for the model  other than as a test of its (pathetic) assumptions. The  model must be falsifiable. To achieve this, it is tempting  to focus on the model, piling the assumptions up higher  and deeper in the hope that they might eventually yield  an unexpected conclusion. More often than not, the con-  clusions reached in this way are banal and unsurprising.  It is better to focus on the biology by asking a specific  question, so that at least one knows whether or not the  assumptions are sufficient for an answer. Indeed, it is bet-  ter to have a question in mind first because that can guide  both the choice of assumptions and the flavor of the model  that is used. Sensing which assumptions might be critical  and which irrelevant to the question at hand is the art of 
</block:4.6>
<block:4.7>
 modeling and, for this, there is no substitute for a deep  understanding of the biology. Good model building is a  subjective exercise, dependent on local information and  expertise, and contingent upon current knowledge. As to  what biological insights all this might bring, that is best  revealed by example. 
</block:4.7>
<block:4.8>
 Three models 
</block:4.8>
<block:4.9>
 The examples that follow extend from cell biology to  immunology to developmental biology. They are personal  favorites and illuminate different issues. 
</block:4.9>
<block:4.10>
 Learning how to think about non-identical compartments 
</block:4.10>
<block:4.11>
 The eukaryotic cell has an internal structure of  membrane-bounded compartments--nucleus, endoplas-  mic reticulum, Golgi and endosomes--which dynamically  interact through vesicle trafficking. Vesicles bud from  and fuse to compartments, thereby exchanging lipids  and proteins. The elucidation of trafficking mechanisms  was celebrated in the 2013 Nobel Prize in Physiology or  Medicine awarded to Jim Rothman, Randy Schekman  and Thomas Sudhof. A puzzling question that remains  unanswered is how distinct compartments remain dis-  tinct, with varied lipid and protein profiles, despite  continuously exchanging material. How are non-identical  compartments created and maintained?  Reinhart Heinrich and Tom Rapoport address this ques-  tion through a mathematical model [23], which formalizes  the sketch in Figure 1. Coat proteins A and B, correspond-  ing to Coat Protein I (COPI) and COPII, encourage vesicle  budding from compartments 1 and 2. Soluble N-ethyl-  maleimide-sensitive factor attachment protein receptors  (SNAREs) X, U, Y and V are present in the compartment  membranes and mediate vesicle fusion by pairing X with  U and Y with V, corresponding to v- and t-SNAREs. A  critical assumption is that SNAREs are packaged into vesi-  cles to an extent that depends on their affinities for coats,  for which there is some experimental evidence. If the cog-  nate SNAREs X and U bind better to coat A than to coat  B, while SNAREs Y and V bind better to coat B than to  coat A, then the model exhibits a threshold in the relative  affinities at which non-identical compartments naturally  emerge. Above this threshold, even if the model is started  with identical distributions of SNAREs in the two com-  partments, it evolves over time to a steady state in which  the SNARE distributions are different. This is illustrated  in Figure 1, with a preponderance of SNAREs X and U in  compartment 1 and a preponderance of SNAREs Y and V  in compartment 2.  The actual details of coats and SNAREs are a good deal  more complicated than in this model. It is a parsimo-  nious model, containing just enough biological detail to  reveal the phenomenon, thereby allowing its essence--  the differential affinity of SNAREs for coats--to be clearly 
</block:4.11>
<block:5.1>
 Gunawardena BMC Biology 2014, 12:29  http://www.biomedcentral.com/1741-7007/12/29 
</block:5.1>
<block:5.2>
 Page 5 of 11 
</block:5.2>
<block:5.3>
 Figure 1. Creation of non-identical compartments. Schematic of the Heinrich-Rapoport model, from [23, Figure one], with the distribution of  SNAREs corresponding approximately to the steady state with non-identical compartments. (C)2005 Heinrich and Rapoport. Originally published in  Journal of Cell Biology, 168:271-280, doi:10.1083/jcb.200409087. SNARE, soluble N-ethyl-maleimide-sensitive factor attachment protein receptor. 
</block:5.3>
<block:5.4>
 understood. We see that a model can be useful not just  to account for data--there is no data here--but to help us  think. However, the biological details are only part of the  story; the mathematical details must also be addressed.  Even a parsimonious model typically has several free  parameters, such as, in this case, binding affinities or total  amounts of SNAREs or coats. To sidestep the parameter  problem, discussed further in the next example, param-  eters of a similar type are set equal to each other. Here,  judgment plays a role in assessing that differences in these  parameters might play a secondary role. The merit of this  assumption could have been tested by sensitivity analysis  [24], which can offer reassurance that the model behavior  is not some lucky accident of the particular values chosen  for the parameters.  The model immediately suggests experiments that could  falsify it, of which the most compelling would be in vitro  reconstitution of compartments with a minimal set of  coats and SNAREs. I was curious about whether this had  been attempted and asked Tom Rapoport about it. Tom  is a cell biologist [25] whereas the late Reinhart Heinrich  was a physicist [26]. Their long-standing collaboration  (they were pioneers in the development of metabolic con-  trol analysis in the 1970s) was stimulated by Tom's father,  Samuel Rapoport, himself a biochemist with mathemat-  ical convictions [27]. Tom explained that the model had  arisen from his sense that there might be a simple explana-  tion for distinct compartments, despite the complexity of  trafficking mechanisms, but that his own laboratory was  not in a position to undertake the follow-up experiments.  Although he had discussed the ideas with others who were 
</block:5.4>
<block:5.5>
 better placed to do so, the field still seemed to be focused  on the molecular details.  The model makes us think further, as all good models  should. The morphology of a multicellular organism is a  hereditary feature that is encoded in DNA, in genetic reg-  ulatory programs that operate during development. But  what encodes the morphology of the eukaryotic cell itself?  This is also inherited: internal membranes are dissolved  or fragmented during cell division, only to reform in their  characteristic patterns in the daughter cells after cytoki-  nesis. Trafficking proteins are genetically encoded but  how is the information to reform compartments passed  from mother to daughter? The Heinrich-Rapoport model  suggests that this characteristic morphology may emerge  dynamically, merely as a result of the right proteins being  present along with the right lipids. This would be a form  of epigenetic inheritance [28], in contrast to the usual  genetic encoding in DNA. Of course, DNA never func-  tions on its own, only in concert with a cell. The Heinrich-  Rapoport model reminds us that the cell is the basic unit  of life. Somebody really ought to test the model. 
</block:5.5>
<block:5.6>
 Discrimination by the T-cell receptor and the parameter  problem 
</block:5.6>
<block:5.7>
 Cytotoxic T cells of the adaptive immune system discrim-  inate between self and non-self through the interaction  between the T-cell receptor (TCR) and major histocom-  patibility complex (MHC) proteins on the surface of a  target cell. MHCs present short peptide antigens (eight  amino acids), derived from proteins in the target cell,  on their external surface. The discrimination mechanism 
</block:5.7>
<block:6.1>
 Gunawardena BMC Biology 2014, 12:29  http://www.biomedcentral.com/1741-7007/12/29 
</block:6.1>
<block:6.2>
 must be highly sensitive, to detect a small number of  strong agonist, non-self peptide-MHCs (pMHCs) against  a much larger background of weak agonist, self pMHCs  on the same target cell. It must also be highly specific,  since the difference between strong- and weak-agonist  pMHCs may rest on only a single amino acid. Discrim-  ination also appears to be very fast, with downstream  signaling proteins being activated within 15 seconds of  TCR interaction with a strong agonist pMHC. A molec-  ular device that discriminates with such speed, sensitivity  and specificity would be a challenge to modern engineer-  ing. It is an impressive demonstration of evolutionary tin-  kering, which Gr?goire Altan-Bonnet and Ron Germain  sought to explain by combining mathematical modeling  with experiments [29].  The lifetime of pMHC-TCR binding had been found  to be one of the few biophysical quantities to correlate  with T-cell activation. Specificity through binding had  previously been analyzed by John Hopfield in a classic  study [30]. He showed that a system at thermodynamic  equilibrium could not achieve discrimination beyond a  certain minimum level but that with sufficient dissipation  of energy, arbitrarily high levels of discrimination were  possible. He suggested a 'kinetic proofreading' scheme  to accomplish this, which Tim McKeithan subsequently  extended to explain TCR specificity [31]. pMHC binding  to the TCR activates lymphocyte-specific protein tyrosine  kinase (LCK), which undertakes multiple phosphoryla-  tions of TCR accessory proteins and these phosphoryla-  tions are presumed to be the dissipative steps. However,  the difficulty with a purely kinetic proofreading scheme is  that specificity is purchased at the expense of both sen-  sitivity and speed [32]. Previous work from the Germain  laboratory had implicated SH2 domain-containing tyro-  sine phosphatase-1 (SHP-1) in downregulating LCK for  weak agonists and the mitogen-activated protein kinase  (MAPK), extracellular signal-regulated kinase (ERK), in  inhibiting SHP-1 for strong agonists [33]. This led Altan-  Bonnet and Germain to put forward the scheme in  Figure 2, in which a core kinetic proofreading scheme  stimulates negative feedback through SHP-1 together with  a slower positive feedback through ERK. The behavior of  interlinked feedback loops has been a recurring theme in  the literature [34,35].  A parsimonious model of such a system might have  been formulated with abstract negative and positive feed-  back differentially influencing a simple kinetic proofread-  ing scheme. In fact, exactly this was done some years  later [36]. The advantage of such parsimony is that it  is easier to analyze how the interaction between nega-  tive and positive feedback regulates model behavior. The  biological wood starts to emerge from the molecular  trees, much as it did for Heinrich and Rapoport in the  previous example. But the goal here also involves the 
</block:6.2>
<block:6.3>
 Page 6 of 11 
</block:6.3>
<block:6.4>
 interpretation of quantitative experimental data. Altan-  Bonnet and Germain opted instead for a detailed model  based on the known biochemistry. Their model has  around 300 dynamical variables. Only the core mod-  ule is described in the main paper, with the remaining  nine modules consigned to the Supplementary Graveyard.  Herbert Sauro's JDesigner software, part of the Systems  Biology Workbench [37], is required to view the model in  its entirety.  The tension between parsimony and detail runs through  systems biology like a fault line. To some, and particularly  to experimentalists, detail is verisimilitude. The more a  model looks like reality, the more it might tell us about  reality. The devil is in the details. But we never bother  ourselves with all the details. All those phosphorylation  sites? Really? All 12 subunits of RNA Pol II? Really? We are  always simplifying--ignoring what we think is irrelevant--  or abstracting--replacing something complicated by some  higher-level entity that is easier to grasp. This is as true for  the experimentalist's informal model--the cartoon that  is sketched on the whiteboard--as it is for the mathe-  matician's formal model. It is impossible to think about  molecular systems without such strategies: it is just that  experimentalists and mathematicians do it differently and  with different motivations. There is much to learn on both  sides, for mathematicians about the hidden assumptions  that guide experimental thinking, often so deeply buried  as to require psychoanalysis to elicit, and for experimen-  talists about the power of abstraction and its ability to  offer a new language in which to think. We are in the  infancy of learning how to learn from each other.  The principal disadvantage of a biologically detailed  model is the attendant parameter problem. Parameter  values are usually estimated by fitting the model to exper-  imental data. Fitting only constrains some parameters; a  good rule of thumb is that 20% of the parameters are well  constrained by fitting, while 80% are not [38]. As John von  Neumann said, expressing a mathematician's disdain for  such sloppiness, 'With four parameters I can fit an ele-  phant and with five I can make him wiggle his trunk' [39].  What von Neumann meant is that a model with too many  parameters is hard to falsify. It can fit almost any data and  what explanatory power it might have may only be an acci-  dent of the particular parameter values that emerge from  the fitting procedure. Judging from some of the literature,  we seem to forget that a model does not predict the data  to which it is fitted: the model is chosen to fit them. In  disciplines where fitting is a professional necessity, such  as X-ray crystallography, it is standard practice to fit to a  training data set and to falsify the model, once it is fitted,  on whether or not it predicts what is important [40]. In  other words, do not fit what you want to explain!  Remarkably, Altan-Bonnet and Germain sidestepped  these problems by not fitting their model at all. They 
</block:6.4>
<block:7.1>
 Gunawardena BMC Biology 2014, 12:29  http://www.biomedcentral.com/1741-7007/12/29 
</block:7.1>
<block:7.2>
 Page 7 of 11 
</block:7.2>
<block:7.3>
 Figure 2. Discrimination by the T-cell receptor. Schematic of the Altan-Bonnet-Germain model from [29, Figure two A], showing a kinetic  proofreading scheme through a sequence of tyrosine phosphorylations, which is triggered by the binding of the TCR to pMHC, linked with a  negative feedback loop through the tyrosine phosphatase SHP-1 and a positive feedback loop through MAPK. MAPK, mitogen-activated protein  kinase; pMHC, peptide-major histocompatibility complex; P, singly phosphorylated; PP, multiply phosphorylated; SHP-1, SH2 domain-containing  tyrosine phosphatase-1; TCR, T-cell receptor. 
</block:7.3>
<block:7.4>
 adopted the same tactic as Heinrich and Rapoport and  set many similar parameters to the same value, leaving  a relatively small number of free parameters. Biological  detail was balanced by parametric parsimony. The free  parameters were then heroically estimated in independent  experiments. I am told that every model parameter was  constrained, although this is not at all clear from the paper.  What was also not mentioned, as Ron Germain  reported, is that 'the model never worked until we actu-  ally measured ERK activation at the single cell level and  discovered its digital nature'. We see that the published  model emerged through a cycle of falsification, although  here it is the model that falsifies the interpretation of  population-averaged data, reminding us yet again that the  mean may not be representative of the distribution.  With the measured parameter values, the model  exhibits a sharp threshold at a pMHC-TCR lifetime of  about 3 seconds, above which a few pMHCs (10 to 100)  are sufficient to trigger full downstream activation of ERK  in 3 minutes. Lifetimes below the threshold exhibit a  hierarchy of responses, with those close to the threshold  triggering activation only with much larger amounts of  pMHCs (100,000), while those further below the thresh-  old are squelched by the negative feedback without ERK  activation. This accounts well for the specificity, sensitiv-  ity and speed of T-cell discrimination but the authors went  further. They interrogated the fitted model to make pre-  dictions about issues such as antagonism and tunability  and they confirmed these with new experiments [29]. The 
</block:7.4>
<block:7.5>
 model was repeatedly forced to put its falsifiability on the  line. In doing so, the boundary of its explanatory power  was reached: it could not account for the delay in ERK  activation with very weak ligands and the authors explic-  itly pointed this out. This should be the accepted practice;  it is the equivalent of a negative control in an experiment.  A model that explains everything, explains nothing. Even  von Neumann might have approved.  To be so successful, a detailed model relies on a powerful  experimental platform. The OT-1 T cells were obtained  from a transgenic mouse line that only expresses a TCR  that is sensitive to the strong-agonist peptide SIINFEKL  (amino acids 257 to 264 of chicken ovalbumin). The RMA-  S target cells were derived from a lymphoma that was  mutagenized to be deficient in antigen processing, so that  the cells present only exogenously supplied peptides on  MHCs. T-cell activation was measured by flow cytome-  try with a phospho-specific antibody to activated ERK.  In this way, calibrated amounts of chosen peptides can  be presented on MHCs to a single type of TCR, much  of the molecular and cellular heterogeneity can be con-  trolled and quantitative data obtained at the single-cell  level. Such exceptional experimental capabilities are not  always available in other biological contexts. 
</block:7.5>
<block:7.6>
 From micro to macro: the somitogenesis clock 
</block:7.6>
<block:7.7>
 Animals exhibit repetitive anatomical structures, like  the spinal column and its attendant array of ribs and  muscles in vertebrates and the multiple body segments 
</block:7.7>
<block:8.1>
 Gunawardena BMC Biology 2014, 12:29  http://www.biomedcentral.com/1741-7007/12/29 
</block:8.1>
<block:8.2>
 carrying wings, halteres and legs in arthropods like  Drosophila. During vertebrate development, repetitive  structures form sequentially over time. In the mid 1970s,  the developmental biologist Jonathan Cooke and the  mathematician Chris Zeeman suggested that the succes-  sive formation of somites (bilateral blocks of mesodermal  tissue on either side of the neural tube--see Figure 3)  might be driven by a cell-autonomous clock, which pro-  gressively initiates somite formation in an anterior to  posterior sequence as if in a wavefront [41]. They were  led to this clock-and-wavefront model in an attempt  to explain the remarkable consistency of somite num-  ber within a species, despite substantial variation in  embryo sizes at the onset of somitogenesis [42]. In the  absence of molecular details, which were beyond reach  at the time, their idea fell on stony ground. It disap-  peared from the literature until Olivier Pourqui?'s group  found the clock in the chicken. His laboratory showed,  using fluorescent in situ hybridization to mRNA in tis-  sue, that the gene c-hairy1 exhibits oscillatory mRNA  expression with a period of 90 minutes, exactly the  time required to form one somite [43]. The somitogen-  esis clock was found to be conserved across vertebrates,  with basic helix-loop-helix transcription factors of the  Hairy/Enhancer of Split (HES) family, acting downstream 
</block:8.2>
<block:8.3>
 Page 8 of 11 
</block:8.3>
<block:8.4>
 of Notch signaling, exhibiting oscillations in expres-  sion with periods ranging from 30 minutes in zebrafish  (at 28?C) to 120 minutes in mouse [44]. Such oscil-  latory genes in somite formation were termed cyclic  genes.  As to the mechanism of the oscillation, negative feed-  back of a protein on its own gene was known to  be a feature of other oscillators [45] and some cyclic  genes, like hes7 in the mouse, were found to exhibit  this property. Negative feedback is usually associ-  ated with homeostasis--with restoring a system after  perturbation--but, as engineers know all too well, it can  bring with it the seeds of instability and oscillation [46].  However, Palmeirim et al. had blocked protein synthe-  sis in chick embryos with cycloheximide and found that  c-hairy1 mRNA continued to oscillate, suggesting that  c-hairy1 was not itself part of a negative-feedback oscil-  lator but was, perhaps, driven by some other oscillatory  mechanism. It remained unclear how the clock worked.  The developmental biologist Julian Lewis tried to  resolve this question in the zebrafish with the help of  a mathematical model [47]. Zebrafish have a very short  somite-formation period of 30 minutes, suggesting that  evolutionary tinkering may have led to a less elaborate  oscillator than in other animals. The HES family genes 
</block:8.4>
<block:8.5>
 Figure 3. The somitogenesis clock. Top: A zebrafish embryo at the ten-somite stage, stained by in situ hybridization for mRNA of the Notch ligand  DeltaC, taken from [47, Figure one]. Bottom left: Potential auto-regulatory mechanisms in the zebrafish, taken from [47, Figure three A,B]. In the  upper mechanism, the Her1 protein dimerizes before repressing its own transcription. In the lower mechanism, Her1 and Her7 form a heterodimer,  which represses transcription of both genes, which occur close to each other but are transcribed in opposite directions. Explicit transcription and  translation delays are shown, which are incorporated in the corresponding models. Bottom right: Mouse embryos stained by in situ hybridization for  Uncx4.1 mRNA, a homeobox gene that marks somites, taken from [52, Figure four]. 
</block:8.5>
<block:9.1>
 Gunawardena BMC Biology 2014, 12:29  http://www.biomedcentral.com/1741-7007/12/29 
</block:9.1>
<block:9.2>
 her1 and her7 were known to exhibit oscillations and there  was some evidence for negative auto-regulation.  Lewis opted for the most parsimonious of models to  formalize negative auto-regulation of her1 and her7 on  themselves, as informally depicted in Figure 3. However,  he made one critical addition by explicitly incorporat-  ing the time delays in transcription and translation. Time  delay in a negative feedback loop is one feature that pro-  motes oscillation, the other being the strength of the  negative feedback. Indeed, there seems to be a trade-off  between these features: the more delay, the less strong  the feedback has to be for oscillation to occur [48]. Lewis  acknowledged the mathematical biologist Nick Monk for  alerting him to the importance of delays and Lewis's arti-  cle in Current Biology appeared beside one from Monk  exploring time delays in a variety of molecular oscillators  [49]. The idea must have been in the air because Jensen  et al. independently made the same suggestion in a letter  [50].  The model parameters, including the time delays, were  all estimated on the basis of reasonable choices for her1  and her7, taking into account, for instance, the intronic  structure of the genes to estimate transcriptional time  delays. Nothing was fitted. With the estimated values, the  models showed sustained periodic oscillations. A pure  Her7 oscillator with homodimerization of Her7 prior  to DNA binding (which determines the strength of the  repression) had a period of 30 minutes. As with the  Heinrich-Rapoport model, there is no data but much  biology. What is achieved is the demonstration that a  simple auto-regulatory loop can plausibly yield sustained  oscillations of the right period. A significant finding was  that the oscillations were remarkably robust to the rate of  protein synthesis, which could be lowered by 90% without  stopping the oscillations or, indeed, changing the period  very much. This suggests a different interpretation of  Palmeirim et al.'s cycloheximide block in the chick. As  Lewis pointed out, 'in studying these biological feedback  phenomena, intuition without the support of a little math-  ematics can be a treacherous guide', a theme to which he  returned in a later review [51].  A particularly startling test of the delay model was car-  ried out in the mouse by Ryoichiro Kageyama's laboratory  in collaboration with Lewis [52]. The period for somite  formation in the mouse is 120 minutes and evidence had  implicated the mouse hes7 gene as part of the clock mech-  anism. Assuming a Hes7 half-life of 20 minutes (against  a measured half-life of 22.3 minutes), Lewis's delay model  yielded sustained oscillations with a period just over 120  minutes. The model also showed that if Hes7 was stabi-  lized slightly to have a half-life only 10 minutes longer,  then the clock broke: the oscillations were no longer sus-  tained but damped out after the first three or four peaks  of expression [52, Figure six B]. Hirata et al. had the clever 
</block:9.2>
<block:9.3>
 Page 9 of 11 
</block:9.3>
<block:9.4>
 idea of mutating each of the seven lysine residues in Hes7  to arginine, on the basis that the ubiquitin-proteasomal  degradation system would use one or more of these lysines  for ubiquitination. The K14R mutant was found to repress  hes7 transcription to the same extent as the wild type but  to have an increased half-life of 30 minutes. A knock-in  mouse expressing Hes7 K14R/K14R showed, exactly as pre-  dicted, the first three to four somites clearly delineated,  followed by a disorganized blur (Figure 3).  Further work from the Kageyama laboratory, as well as  by others, has explored the role of introns in determin-  ing the transcriptional delays in the somitogenesis clock,  leading to experiments in transgenic mice that again beau-  tifully confirm the predictions of the Lewis model [53-55].  These results strongly suggest the critical role of delays  in breaking the clock but it remains of interest to know  the developmental consequences of a working clock with  a different period to the wild type [56].  On the face of it, Julian Lewis's simple model has been a  predictive triumph. I cannot think of any other model that  can so accurately predict what happens in re-engineered  mice. On closer examination, however, there is something  distinctly spooky about it. If mouse pre-somitic mesoder-  mal cells are dissociated in culture, individual cells show  repetitive peaks of expression of cyclic genes but with  great variability in amplitude and period [57]. In isolation,  the clock is noisy and unsynchronized, nothing like the  beautiful regularity that is observed in the intact tissue.  The simple Lewis model can be made much more detailed  to allow for such things as stochasticity in gene expres-  sion, additional feedback and cell-to-cell communication  by signaling pathways, which can serve to synchronize and  entrain individual oscillators [47,58-60]. A more abstract  approach can also be taken, in which emergent regular-  ity is seen to arise when noisy oscillators interact through  time-delayed couplings [61,62]. As Andy Oates said to me,  such an abstraction 'becomes simpler (or at least more  satisfying) than an increasingly large genetic regulatory  network, which starts to grow trunks at alarming angles'.  These kinds of 'tiered models' have yielded much insight  into the complex mechanisms at work in the tissue [63].  The thing is, none of this molecular complexity is present  in the Lewis model. Yet, it describes what happens in the  mouse with remarkable accuracy. The microscopic com-  plexity seems to have conspired to produce something  beautifully simple at the macroscopic level. In physics,  the macroscopic gas law, PV = RT, is beautifully simple  and statistical mechanics shows how it emerges from the  chaos of molecular interactions [64]. How does the Lewis  model emerge in the tissue from the molecular complex-  ity within? It is as if we are seeing a tantalizing glimpse of  some future science whose concepts and methods remain  barely visible to us in the present. Every time I think about  it, the hairs on the back of my neck stand up. 
</block:9.4>
<block:10.1>
 Gunawardena BMC Biology 2014, 12:29  http://www.biomedcentral.com/1741-7007/12/29 
</block:10.1>
<block:10.2>
 Conclusion 
</block:10.2>
<block:10.3>
 A mathematical model is a logical machine for convert-  ing assumptions into conclusions. If the model is correct  and we believe its assumptions then we must, as a mat-  ter of logic, believe its conclusions. This logical guarantee  allows a modeler, in principle, to navigate with confi-  dence far from the assumptions, perhaps much further  than intuition might allow, no matter how insightful, and  reach surprising conclusions. But, and this is the essential  point, the certainty is always relative to the assumptions.  Do we believe our assumptions? We believe fundamen-  tal physics on which biology rests. We can deduce many  things from physics but not, alas, the existence of physi-  cists. This leaves us, at least in the molecular realm, in the  hands of phenomenology and informed guesswork. There  is nothing wrong with that but we should not fool our-  selves that our models are objective and predictive, in the  sense of fundamental physics. They are, in James Black's  resonant phrase, 'accurate descriptions of our pathetic  thinking'.  Mathematical models are a tool, which some biolo-  gists have used to great effect. My distinguished Harvard  colleague, Edward Wilson, has tried to reassure the math-  ematically phobic that they can still do good science with-  out mathematics [65]. Absolutely, but why not use it when  you can? Biology is complicated enough that we surely  need every tool at our disposal. For those so minded,  the perspective developed here suggests the following  guidelines: 
</block:10.3>
<block:10.4>
 1. Ask a question. Building models for the sake of doing  so might keep mathematicians happy but it is a poor  way to do biology. Asking a question guides the  choice of assumptions and the flavor of model and  provides a criterion by which success can be judged.  2. Keep it simple. Including all the biochemical details  may reassure biologists but it is a poor way to model.  Keep the complexity of the assumptions in line with  the experimental context and try to find the right  abstractions.  3. If the model cannot be falsified, it is not telling you  anything. Fitting is the bane of modeling. It deludes  us into believing that we have predicted what we  have fitted when all we have done is to select the  model so that it fits. So, do not fit what you want to  explain; stick the model's neck out after it is fitted  and try to falsify it. 
</block:10.4>
<block:10.5>
 In later life, Charles Darwin looked back on his early  repugnance for mathematics, the fault of a teacher who  was 'a very dull man', and said, 'I have deeply regretted  that I did not proceed far enough at least to understand  something of the great leading principles of mathemat-  ics; for men thus endowed seem to have an extra sense' 
</block:10.5>
<block:10.6>
 Page 10 of 11 
</block:10.6>
<block:10.7>
 [66]. One of those people with an extra sense was an  Augustinian friar, toiling in the provincial obscurity of  Austro-Hungarian Br?nn, teaching physics in the local  school while laying the foundations for rescuing Darwin's  theory from oblivion [67], a task later accomplished, in the  hands of J. B. S. Haldane, R. A. Fisher and Sewall Wright,  largely by mathematics. Darwin and Mendel represent the  qualitative and quantitative traditions in biology. It is a  historical tragedy that they never came together in their  lifetimes. If we are going to make sense of systems biology,  we shall have to do a lot better. 
</block:10.7>
<block:10.8>
 Abbreviations  COP: Coat Protein I; ERK: Extracellular signal-regulated kinase; HES:  Hairy/Enhancer of Split family; LCK: lymphocyte-specific protein tyrosine  kinase; MAPK: mitogen-activated protein kinase; MHC: major histocompatibility  complex; pMHC: peptide-MHC; SHP-1: SH2 domain-containing tyrosine  phosphatase-1; SNARE: soluble N-ethyl-maleimide-sensitive factor attachment  protein receptor; TCR: T-cell receptor. 
</block:10.8>
<block:10.9>
 Competing interests  The author declares that he has no competing interests. 
</block:10.9>
<block:10.10>
 Acknowledgements  I thank Gr?goire Altan-Bonnet, Ron Germain, Ryo Kageyama, Julian Lewis,  Andy Oates and Tom Rapoport for very helpful comments on their respective  models but must point out that the opinions expressed in this paper are mine  and that any errors or omissions should be laid at my door. I also thank two  anonymous reviewers for their thoughtful comments and Mary Welstead for  stringent editorial consultancy. 
</block:10.10>
<block:10.11>
 Published: 30 April 2014 
</block:10.11>
<block:10.12>
 References  1. Gunawardena J: Some lessons about models from Michaelis and  Menten. Mol Biol Cell 2012, 23:517-519.  2. Gunawardena J: Biology is more theoretical than physics. Mol Biol Cell  2013, 24:1827-1829.  3. Ferrell JE, Machleder EM: The biochemical basis of an all-or-none cell  fate switch in Xenopus oocytes. Science 1998, 280:895-898.  4. Altschuler SJ, Wu LF: Cellular heterogeneity: do differences make a  difference? Cell 2010, 3:559-563.  5. Krebs H: Otto Warburg: Cell Physiologist, Biochemist and Eccentric. Oxford,  UK: Clarendon Press; 1981.  6. Watson JD: Genes, Girls and Gamow. Oxford, UK: Oxford University Press;  2001.  7. Kay LE: Who Wrote the Book of Life. A History of the Genetic Code. Stanford,  CA, USA: Stanford University Press; 2000.  8. Chargaff E: Essays on Nucleic Acids. Amsterdam, Holland: Elsevier  Publishing Company; 1963.  9. Nirenberg M: The genetic code. In Nobel Lectures, Physiology or Medicine  1963-1970. Amsterdam, Holland: Elsevier Publishing Co; 1972.  10. Brenner S: Sequences and consequences. Phil Trans Roy Soc 2010,  365:207-212.  11. Pearl J: Causality: Models, Reasoning and Inference. Cambridge, UK:  Cambridge University Press; 2000.  12. Feynman RP, Leighton RB, Sands M: The Feynman Lectures on Physics.  Volume 1. Mainly Mechanics, Radiation and Heat. Reading, MA, USA:  Addison-Wesley; 1963.  13. Levitt M: The birth of computational structural biology. Nat Struct Biol  2001, 8:392-393.  14. Karplus M, Kuriyan J: Molecular dynamics and protein function. Proc  Natl Acad Sci USA 2005, 102:6679-6685.  15. Dror RO, Dirks RM, Grossman JP, Xu H, Shaw DE: Biomolecular  simulation: a computational microscope for molecular biology.  Annu Rev Biophys 2012, 41:429-452. 
</block:10.12>
<block:11.1>
 Gunawardena BMC Biology 2014, 12:29  http://www.biomedcentral.com/1741-7007/12/29 
</block:11.1>
<block:11.2>
 16. Atkins P, de Paula J: Elements of Physical Chemistry. 5th edition. Oxford, UK:  Oxford University Press; 2009.  17. Mysels KJ: Textbook errors VII: the laws of reaction rates and of  equilibria. J Chem Educ 1956, 33:178-179.  18. Cornish-Bowden A: Fundamentals of Enzyme Kinetics. 2nd edition. London,  UK: Portland Press; 1995.  19. Weiss JN: The Hill equation revisited: uses and misuses. FASEB J 1997,  11:835-841.  20. Black J: A personal view of pharmacology. Annu Rev Pharmacol Toxicol  1996, 36:1-33.  21. Colquhoun D: The quantitative analysis of drug-receptor  interactions: a short history. Trends Pharmacol Sci 2006, 27:149-157.  22. Black J: Drugs from emasculated hormones: the principles of  syntopic antagonism. In Nobel Lectures, Physiology or Medicine  1981-1990. Edited by Fr?ngsmyr T. Singapore: World Scientific; 1993.  23. Heinrich R, Rapoport TA: Generation of nonidentical compartments in  vesicular transport systems. J Cell Biol 2005, 162:271-280.  24. Varma A, Morbidelli M, Wu H: Parametric Sensitivity in Chemical Systems.  Cambridge, UK: Cambridge University Press; 2005.  25. Davis TH: Profile of Tom A Rapoport. Proc Natl Acad Sci USA 2005,  102:14129-14131.  26. Kirschner M: Reinhart Heinrich (1946-2006). Pioneer in systems  biology. Nature 2006, 444:700.  27. Heinrich R, Rapoport SM, Rapoport TA: Metabolic regulation and  mathematical models. Prog Biophys Molec Biol 1977, 32:1-82.  28. Ptashne M: On the use of the word 'epigenetic'. Curr Biol 2007,  17:233-236.  29. Altan-Bonnet G, Germain RN: Modeling T cell antigen discrimination  based on feedback control of digital ERK responses. PLoS Biol 2005,  3:1925-1938.  30. Hopfield JJ: Kinetic proofreading: a new mechanism for reducing  errors in biosynthetic processes requiring high specificity. Proc Natl  Acad Sci USA 1974, 71:4135-39.  31. McKeithan TW: Kinetic proofreading in T-cell receptor signal  transduction. Proc Natl Acad Sci USA 1995, 92:5042-5046.  32. Murugan A, Huse DA, Leibler S: Speed, dissipation, and error in kinetic  proofreading. Proc Natl Acad Sci USA 2012, 109:12034-12039.  33. ?tefanov? I, Hemmer B, Vergelli M, Martin R, Biddison WE, Germain RN: TCR  ligand discrimination is enforced by competing ERK positive and  SHP-1 negative feedback pathways. Nat Immunol 2003, 4:248-254.  34. Brandman O, Ferrell JE, Li R, Meyer T: Interlinked fast and slow positive  feedback loops drive reliable cell decisions. Science 2005,  310:496-498.  35. Tsai TY, Choi YS, Ma W, Pomerening JR, Tang C, Ferrell JE: Robust,  tunable biological oscillations from interlinked positive and  negative feedback loops. Science 2008, 321:126-129.  36. Fran?ois P, Voisinne G, Siggia ED, Altan-Bonnet G, Vergassola M:  Phenotypic model for early t-cell activation displaying sensitivity,  specificity, and antagonism. Proc Natl Acad Sci USA 2013, 110:888-897.  37. Sauro HM, Hucka M, Finney A, Wellock C, Bolouri H, Doyle J, Kitano H:  Next generation simulation tools: the Systems Biology Workbench  and BioSPICE integration. Omics 2003, 7:355-372.  38. Gutenkunst RN, Waterfall JJ, Casey FP, Brown KS, Myers CR, Sethna JP:  Universally sloppy parameter sensitivities in systems biology  models. PLoS Comput Biol 2007, 3:1871-1878.  39. Dyson F: A meeting with Enrico Fermi. Nature 2004, 427:297.  40. Br?nger A: Free R value: a novel statistical quantity for assessing the  accuracy of crystal structures. Nature 1992, 355:472-475.  41. Cooke J, Zeeman EC: A clock and wavefront model for control of the  number of repeated structures during animal morphogenesis. J  Theor Biol 1976, 58:455-476.  42. Cooke J: The problem of periodic patterns in embryos. Phil Trans R Soc  Lond B Biol Sci 1981, 295:509-524.  43. Palmeirim I, Henrique D, Ish-Horowicz D, Pourqui? O: Avian hairy gene  expression identifies a molecular clock linked to vertebrate  segmentation and somitogenesis. Cell 1997, 91:639-648.  44. Pourqui? O: The segmentation clock: converting embryonic time  into spatial pattern. Science 2003, 301:328-330.  45. Sassone-Corsi P: Rhythmic transcription with autoregulatory loops:  winding up the biological clock. Cell 1994, 78:361-364. 
</block:11.2>
<block:11.3>
 Page 11 of 11 
</block:11.3>
<block:11.4>
 46. ?str?m KJ, Murray RM: Feedback Systems. An Introduction for Scientists and  Engineers. Princeton, NJ, USA: Princeton University Press; 2008.  47. Lewis J: Autoinhibition with transcriptional delay: a simple  mechanism for the Zebrafish somitogenesis oscillator. Curr Biol 2003,  13:1398-1408.  48. Tyson JJ, Othmer HG: The dynamics of feedback control circuits in  biochemical pathways. In Progress in Theoretical Biology, Volume 5.  Edited by Rosen R, Snell F. New York, NY, USA: Academic Press; 1978.  49. Monk NAM: Oscillatory expression of Hes1, p53, and NF-kB driven by  transcriptional time delays. Curr Biol 2003, 13:1409-1413.  50. Jensen MH, Sneppen K, Tiana G: Sustained oscillations and time delays  in gene expression of protein Hes1. FEBS Lett 2003, 541:176-177.  51. Lewis J: From signals to patterns: space, time and mathematics in  developmental biology. Science 2008, 322:399-403.  52. Hirata H, Bessho Y, Kokubu H, Masamizu Y, Yamada S, Lewis J, Kageyama  R: Instability of Hes7 protein is crucial for the somite segmentation  clock. Nat Genet 2004, 36:750-754.  53. Swinburne IA, Miguez DG, Landgraf D, Silver PA: Intron length increases  oscillatory periods of gene expression in animal cells. Genes Dev  2008, 22:2342-2346.  54. Takashima Y, Ohtsuka T, Gonz?lez A, Miyachi H, Kageyama R: Intronic  delay is essential for oscillatory expression in the segmentation  clock. Proc Natl Acad Sci USA 2011, 108:3300-3305.  55. Harima Y, Takashima Y, Ueda Y, Ohtsuka T, Kageyama R: Accelerating the  tempo of the segmentation clock by reducing the number of  introns in the Hes7 gene. Cell Rep 2013, 3:1-7.  56. Oswald A, Oates AC: Control of endogenous gene expression timing  by introns. Genome Biol 2011, 12:107.  57. Masamizu Y, Ohtsuka T, Takashima Y, Nagahara H, Takenaka Y, Yoshikawa  K, Okamura H, Kageyama R: Real-time imaging of the somite  segmentation clock: revelation of unstable oscillators in the  individual presomitic mesoderm cells. Proc Natl Acad Sci USA 2006,  103:1313-1318.  58. Giudicelli F, ?zbudak EM, Wright GJ, Lewis J: Setting the tempo in  development: an investigation of the zebrafish somite clock  mechanism. PLoS Biol 2007, 5:150.  59. Schr?ter C, Ares S, Morelli LG, Isakova A, Hens K, Soroldoni D, Gajewski M,  J?licher F, Maerkl SJ, Deplancke B, Oates AC: Topology and dynamics of  the zebrafish segmentation clock core circuit. PLoS Biol 2012,  10:1001364.  60. Hanisch A, Holder MV, Choorapoikayil S, Gajewski M, ?zbudak EM, Lewis J:  The elongation rate of RNA polymerase II in zebrafish and its  significance in the somite segmentation clock. Development 2013,  140:444-453.  61. Morelli LG, Ares S, Herrgen L, Schr?ter C, J?licher F, Oates AC: Delayed  coupling theory of vertebrate segmentation. HFSP J 2009, 3:55-66.  62. Herrgen L, Ares S, Morelli LG, Schr?ter C, J?licher F, Oates AC:  Intercellular coupling regulates the period of the segmentation  clock. Curr Biol 2010, 20:1244-1253.  63. Oates AC, Morelli LG, Ares S: Patterning embryos with oscillations:  structure, function and dynamics of the vertebrate segmentation  clock. Development 2012, 139:625-639.  64. Khinchin AI: Mathematical Foundations of Statistical Mechanics. New York,  NY, USA: Dover Publications Inc; 1949.  65. Wilson EO: Letters to a Young Scientist. New York, NY, USA: Liveright  Publishing Corporation; 2013.  66. Barlow N (Ed): The Autobiography of Charles Darwin. 1809-1882, New York,  NY, USA: W. W. Norton and Co, Inc; 1958.  67. Mawer S: Gregor Mendel. Planting the Seeds of Genetics. New York, NY, USA:  Abrams; 2006. 
</block:11.4>
<block:11.5>
 doi:10.1186/1741-7007-12-29  Cite this article as: Gunawardena J: Models in biology: 'accurate  descriptions of our pathetic thinking'. BMC Biology 2014 12:29. 
</block:11.5>
